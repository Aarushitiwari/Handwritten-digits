{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import sys\n",
    "import pickle\n",
    "import gzip\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    f = gzip.open('/Users/Aarushi/Desktop/neural-networks-and-deep-learning/data/mnist.pkl.gz', 'rb')\n",
    "    training_data, validation_data, test_data = pickle.load(f)\n",
    "    f.close()\n",
    "    return (training_data, validation_data, test_data)\n",
    "\n",
    "def load_data_wrapper():\n",
    "    tr_d, va_d, te_d = load_data()\n",
    "    training_inputs = [np.reshape(x, (784, 1)) for x in tr_d[0]]\n",
    "    training_results = [vectorized_result(y) for y in tr_d[1]]\n",
    "    training_data = zip(training_inputs, training_results)\n",
    "    validation_inputs = [np.reshape(x, (784, 1)) for x in va_d[0]]\n",
    "    validation_data = zip(validation_inputs, va_d[1])\n",
    "    test_inputs = [np.reshape(x, (784, 1)) for x in te_d[0]]\n",
    "    test_data = zip(test_inputs, te_d[1])\n",
    "    return (training_data, validation_data, test_data)\n",
    "\n",
    "def vectorized_result(j):\n",
    "    e = np.zeros((10, 1))\n",
    "    e[j] = 1.0\n",
    "    return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuadraticCost(object):\n",
    "\n",
    "    @staticmethod\n",
    "    def fn(a, y):\n",
    "        return 0.5*np.linalg.norm(a-y)**2\n",
    "\n",
    "    @staticmethod\n",
    "    def delta(z, a, y):     \n",
    "        return (a-y) * sigmoid_prime(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEntropyCost(object):\n",
    "    @staticmethod\n",
    "    def fn(a, y):     \n",
    "        return np.sum(np.nan_to_num(-y*np.log(a)-(1-y)*np.log(1-a)))\n",
    "\n",
    "    @staticmethod\n",
    "    def delta(z, a, y):\n",
    "       \n",
    "        return (a-y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(object):\n",
    "\n",
    "    def __init__(self, sizes, cost=CrossEntropyCost):\n",
    "       \n",
    "        self.num_layers = len(sizes)\n",
    "        self.sizes = sizes\n",
    "        self.default_weight_initializer()\n",
    "        self.cost=cost\n",
    "\n",
    "    def default_weight_initializer(self):\n",
    "        \n",
    "        self.biases = [np.random.randn(y, 1) for y in self.sizes[1:]]\n",
    "        self.weights = [np.random.randn(y, x)/np.sqrt(x)\n",
    "                        for x, y in zip(self.sizes[:-1], self.sizes[1:])]\n",
    "\n",
    "    def large_weight_initializer(self):        \n",
    "        self.biases = [np.random.randn(y, 1) for y in self.sizes[1:]]\n",
    "        self.weights = [np.random.randn(y, x)\n",
    "                        for x, y in zip(self.sizes[:-1], self.sizes[1:])]\n",
    "\n",
    "    def feedforward(self, a):      \n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "            a = sigmoid(np.dot(w, a)+b)\n",
    "        return a\n",
    "\n",
    "    def SGD(self, training_data, epochs, mini_batch_size, eta,\n",
    "            lmbda = 0.0,\n",
    "            evaluation_data=None,\n",
    "            monitor_evaluation_cost=False,\n",
    "            monitor_evaluation_accuracy=False,\n",
    "            monitor_training_cost=False,\n",
    "            monitor_training_accuracy=False):\n",
    "       \n",
    "        if evaluation_data: n_data = len(evaluation_data)\n",
    "        n = len(training_data)\n",
    "        evaluation_cost, evaluation_accuracy = [], []\n",
    "        training_cost, training_accuracy = [], []\n",
    "        for j in xrange(epochs):\n",
    "            random.shuffle(training_data)\n",
    "            mini_batches = [\n",
    "                training_data[k:k+mini_batch_size]\n",
    "                for k in xrange(0, n, mini_batch_size)]\n",
    "            for mini_batch in mini_batches:\n",
    "                self.update_mini_batch(\n",
    "                    mini_batch, eta, lmbda, len(training_data))\n",
    "            print \"Epoch %s training complete\" % j\n",
    "            if monitor_training_cost:\n",
    "                cost = self.total_cost(training_data, lmbda)\n",
    "                training_cost.append(cost)\n",
    "                print \"Cost on training data: {}\".format(cost)\n",
    "            if monitor_training_accuracy:\n",
    "                accuracy = self.accuracy(training_data, convert=True)\n",
    "                training_accuracy.append(accuracy)\n",
    "                print \"Accuracy on training data: {} / {}\".format(\n",
    "                    accuracy, n)\n",
    "            if monitor_evaluation_cost:\n",
    "                cost = self.total_cost(evaluation_data, lmbda, convert=True)\n",
    "                evaluation_cost.append(cost)\n",
    "                print \"Cost on evaluation data: {}\".format(cost)\n",
    "            if monitor_evaluation_accuracy:\n",
    "                accuracy = self.accuracy(evaluation_data)\n",
    "                evaluation_accuracy.append(accuracy)\n",
    "                print \"Accuracy on evaluation data: {} / {}\".format(\n",
    "                    self.accuracy(evaluation_data), n_data)\n",
    "            print\n",
    "        return evaluation_cost, evaluation_accuracy, \\\n",
    "            training_cost, training_accuracy\n",
    "\n",
    "    def update_mini_batch(self, mini_batch, eta, lmbda, n):\n",
    "        \n",
    "        nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
    "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
    "        for x, y in mini_batch:\n",
    "            delta_nabla_b, delta_nabla_w = self.backprop(x, y)\n",
    "            nabla_b = [nb+dnb for nb, dnb in zip(nabla_b, delta_nabla_b)]\n",
    "            nabla_w = [nw+dnw for nw, dnw in zip(nabla_w, delta_nabla_w)]\n",
    "        self.weights = [(1-eta*(lmbda/n))*w-(eta/len(mini_batch))*nw\n",
    "                        for w, nw in zip(self.weights, nabla_w)]\n",
    "        self.biases = [b-(eta/len(mini_batch))*nb\n",
    "                       for b, nb in zip(self.biases, nabla_b)]\n",
    "\n",
    "    def backprop(self, x, y):\n",
    "        \n",
    "        nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
    "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
    "        # feedforward\n",
    "        activation = x\n",
    "        activations = [x] # list to store all the activations, layer by layer\n",
    "        zs = [] # list to store all the z vectors, layer by layer\n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "            z = np.dot(w, activation)+b\n",
    "            zs.append(z)\n",
    "            activation = sigmoid(z)\n",
    "            activations.append(activation)\n",
    "        # backward pass\n",
    "        delta = (self.cost).delta(zs[-1], activations[-1], y)\n",
    "        nabla_b[-1] = delta\n",
    "        nabla_w[-1] = np.dot(delta, activations[-2].transpose())\n",
    "\n",
    "        for l in xrange(2, self.num_layers):\n",
    "            z = zs[-l]\n",
    "            sp = sigmoid_prime(z)\n",
    "            delta = np.dot(self.weights[-l+1].transpose(), delta) * sp\n",
    "            nabla_b[-l] = delta\n",
    "            nabla_w[-l] = np.dot(delta, activations[-l-1].transpose())\n",
    "        return (nabla_b, nabla_w)\n",
    "\n",
    "    def accuracy(self, data, convert=False):\n",
    "       \n",
    "        if convert:\n",
    "            results = [(np.argmax(self.feedforward(x)), np.argmax(y))\n",
    "                       for (x, y) in data]\n",
    "        else:\n",
    "            results = [(np.argmax(self.feedforward(x)), y)\n",
    "                        for (x, y) in data]\n",
    "        return sum(int(x == y) for (x, y) in results)\n",
    "\n",
    "    def total_cost(self, data, lmbda, convert=False):\n",
    "        \n",
    "        cost = 0.0\n",
    "        for x, y in data:\n",
    "            a = self.feedforward(x)\n",
    "            if convert: y = vectorized_result(y)\n",
    "            cost += self.cost.fn(a, y)/len(data)\n",
    "        cost += 0.5*(lmbda/len(data))*sum(\n",
    "            np.linalg.norm(w)**2 for w in self.weights)\n",
    "        return cost\n",
    "\n",
    "    def save(self, filename):\n",
    "        \n",
    "        data = {\"sizes\": self.sizes,\n",
    "                \"weights\": [w.tolist() for w in self.weights],\n",
    "                \"biases\": [b.tolist() for b in self.biases],\n",
    "                \"cost\": str(self.cost.__name__)}\n",
    "        f = open(filename, \"w\")\n",
    "        json.dump(data, f)\n",
    "        f.close()\n",
    "\n",
    "def load(filename):\n",
    "   \n",
    "    f = open(filename, \"r\")\n",
    "    data = json.load(f)\n",
    "    f.close()\n",
    "    cost = getattr(sys.modules[__name__], data[\"cost\"])\n",
    "    net = Network(data[\"sizes\"], cost=cost)\n",
    "    net.weights = [np.array(w) for w in data[\"weights\"]]\n",
    "    net.biases = [np.array(b) for b in data[\"biases\"]]\n",
    "    return net\n",
    "\n",
    "def vectorized_result(j):   \n",
    "    e = np.zeros((10, 1))\n",
    "    e[j] = 1.0\n",
    "    return e\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1.0/(1.0+np.exp(-z))\n",
    "\n",
    "def sigmoid_prime(z):\n",
    "    return sigmoid(z)*(1-sigmoid(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data, validation_data, test_data = load_data_wrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Network([784, 30, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 training complete\n",
      "\n",
      "Epoch 1 training complete\n",
      "\n",
      "Epoch 2 training complete\n",
      "\n",
      "Epoch 3 training complete\n",
      "\n",
      "Epoch 4 training complete\n",
      "\n",
      "Epoch 5 training complete\n",
      "\n",
      "Epoch 6 training complete\n",
      "\n",
      "Epoch 7 training complete\n",
      "\n",
      "Epoch 8 training complete\n",
      "\n",
      "Epoch 9 training complete\n",
      "\n",
      "Epoch 10 training complete\n",
      "\n",
      "Epoch 11 training complete\n",
      "\n",
      "Epoch 12 training complete\n",
      "\n",
      "Epoch 13 training complete\n",
      "\n",
      "Epoch 14 training complete\n",
      "\n",
      "Epoch 15 training complete\n",
      "\n",
      "Epoch 16 training complete\n",
      "\n",
      "Epoch 17 training complete\n",
      "\n",
      "Epoch 18 training complete\n",
      "\n",
      "Epoch 19 training complete\n",
      "\n",
      "Epoch 20 training complete\n",
      "\n",
      "Epoch 21 training complete\n",
      "\n",
      "Epoch 22 training complete\n",
      "\n",
      "Epoch 23 training complete\n",
      "\n",
      "Epoch 24 training complete\n",
      "\n",
      "Epoch 25 training complete\n",
      "\n",
      "Epoch 26 training complete\n",
      "\n",
      "Epoch 27 training complete\n",
      "\n",
      "Epoch 28 training complete\n",
      "\n",
      "Epoch 29 training complete\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([], [], [], [])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.SGD(training_data , 30, 10, 10.0,\n",
    "            lmbda = 5.0,\n",
    "            evaluation_data=None,\n",
    "            monitor_evaluation_cost=False,\n",
    "            monitor_evaluation_accuracy=False,\n",
    "            monitor_training_cost=False,\n",
    "            monitor_training_accuracy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 training complete\n",
      "Cost on training data: 3.88846025502\n",
      "Accuracy on training data: 5175 / 50000\n",
      "Cost on evaluation data: 3.88966849256\n",
      "Accuracy on evaluation data: 1090 / 10000\n",
      "\n",
      "Epoch 1 training complete\n",
      "Cost on training data: 3.52679766282\n",
      "Accuracy on training data: 4506 / 50000\n",
      "Cost on evaluation data: 3.53748347866\n",
      "Accuracy on evaluation data: 915 / 10000\n",
      "\n",
      "Epoch 2 training complete\n",
      "Cost on training data: 3.74027457473\n",
      "Accuracy on training data: 4968 / 50000\n",
      "Cost on evaluation data: 3.7450234795\n",
      "Accuracy on evaluation data: 990 / 10000\n",
      "\n",
      "Epoch 3 training complete\n",
      "Cost on training data: 3.61647424889\n",
      "Accuracy on training data: 4932 / 50000\n",
      "Cost on evaluation data: 3.60506032205\n",
      "Accuracy on evaluation data: 991 / 10000\n",
      "\n",
      "Epoch 4 training complete\n",
      "Cost on training data: 3.74775931362\n",
      "Accuracy on training data: 5175 / 50000\n",
      "Cost on evaluation data: 3.72689401406\n",
      "Accuracy on evaluation data: 1090 / 10000\n",
      "\n",
      "Epoch 5 training complete\n",
      "Cost on training data: 3.65756283957\n",
      "Accuracy on training data: 4968 / 50000\n",
      "Cost on evaluation data: 3.65957185866\n",
      "Accuracy on evaluation data: 990 / 10000\n",
      "\n",
      "Epoch 6 training complete\n",
      "Cost on training data: 3.47242604052\n",
      "Accuracy on training data: 5175 / 50000\n",
      "Cost on evaluation data: 3.4630303174\n",
      "Accuracy on evaluation data: 1090 / 10000\n",
      "\n",
      "Epoch 7 training complete\n",
      "Cost on training data: 3.81657325357\n",
      "Accuracy on training data: 4859 / 50000\n",
      "Cost on evaluation data: 3.82227429962\n",
      "Accuracy on evaluation data: 983 / 10000\n",
      "\n",
      "Epoch 8 training complete\n",
      "Cost on training data: 3.57887403999\n",
      "Accuracy on training data: 5175 / 50000\n",
      "Cost on evaluation data: 3.56917889284\n",
      "Accuracy on evaluation data: 1090 / 10000\n",
      "\n",
      "Epoch 9 training complete\n",
      "Cost on training data: 3.60794596523\n",
      "Accuracy on training data: 4968 / 50000\n",
      "Cost on evaluation data: 3.61296235005\n",
      "Accuracy on evaluation data: 990 / 10000\n",
      "\n",
      "Epoch 10 training complete\n",
      "Cost on training data: 3.48149482889\n",
      "Accuracy on training data: 5175 / 50000\n",
      "Cost on evaluation data: 3.47376277271\n",
      "Accuracy on evaluation data: 1090 / 10000\n",
      "\n",
      "Epoch 11 training complete\n",
      "Cost on training data: 3.4953854824\n",
      "Accuracy on training data: 5678 / 50000\n",
      "Cost on evaluation data: 3.50388784707\n",
      "Accuracy on evaluation data: 1064 / 10000\n",
      "\n",
      "Epoch 12 training complete\n",
      "Cost on training data: 3.57065357037\n",
      "Accuracy on training data: 4951 / 50000\n",
      "Cost on evaluation data: 3.59154990747\n",
      "Accuracy on evaluation data: 967 / 10000\n",
      "\n",
      "Epoch 13 training complete\n",
      "Cost on training data: 3.8121080743\n",
      "Accuracy on training data: 5101 / 50000\n",
      "Cost on evaluation data: 3.80280742011\n",
      "Accuracy on evaluation data: 1030 / 10000\n",
      "\n",
      "Epoch 14 training complete\n",
      "Cost on training data: 3.81806294133\n",
      "Accuracy on training data: 4932 / 50000\n",
      "Cost on evaluation data: 3.82088273047\n",
      "Accuracy on evaluation data: 991 / 10000\n",
      "\n",
      "Epoch 15 training complete\n",
      "Cost on training data: 3.91577890312\n",
      "Accuracy on training data: 4859 / 50000\n",
      "Cost on evaluation data: 3.93350694387\n",
      "Accuracy on evaluation data: 983 / 10000\n",
      "\n",
      "Epoch 16 training complete\n",
      "Cost on training data: 3.87506315412\n",
      "Accuracy on training data: 4932 / 50000\n",
      "Cost on evaluation data: 3.88916514996\n",
      "Accuracy on evaluation data: 991 / 10000\n",
      "\n",
      "Epoch 17 training complete\n",
      "Cost on training data: 3.50304879872\n",
      "Accuracy on training data: 4951 / 50000\n",
      "Cost on evaluation data: 3.51307957334\n",
      "Accuracy on evaluation data: 967 / 10000\n",
      "\n",
      "Epoch 18 training complete\n",
      "Cost on training data: 3.45718586854\n",
      "Accuracy on training data: 5101 / 50000\n",
      "Cost on evaluation data: 3.46740573038\n",
      "Accuracy on evaluation data: 1030 / 10000\n",
      "\n",
      "Epoch 19 training complete\n",
      "Cost on training data: 3.87566049187\n",
      "Accuracy on training data: 4932 / 50000\n",
      "Cost on evaluation data: 3.87388226073\n",
      "Accuracy on evaluation data: 991 / 10000\n",
      "\n",
      "Epoch 20 training complete\n",
      "Cost on training data: 3.57289917285\n",
      "Accuracy on training data: 4968 / 50000\n",
      "Cost on evaluation data: 3.57290739276\n",
      "Accuracy on evaluation data: 990 / 10000\n",
      "\n",
      "Epoch 21 training complete\n",
      "Cost on training data: 4.45816428242\n",
      "Accuracy on training data: 4968 / 50000\n",
      "Cost on evaluation data: 4.4638706716\n",
      "Accuracy on evaluation data: 990 / 10000\n",
      "\n",
      "Epoch 22 training complete\n",
      "Cost on training data: 3.97285244203\n",
      "Accuracy on training data: 4842 / 50000\n",
      "Cost on evaluation data: 3.95556244812\n",
      "Accuracy on evaluation data: 1009 / 10000\n",
      "\n",
      "Epoch 23 training complete\n",
      "Cost on training data: 4.17835150306\n",
      "Accuracy on training data: 4859 / 50000\n",
      "Cost on evaluation data: 4.17483715895\n",
      "Accuracy on evaluation data: 983 / 10000\n",
      "\n",
      "Epoch 24 training complete\n",
      "Cost on training data: 3.83209446366\n",
      "Accuracy on training data: 4506 / 50000\n",
      "Cost on evaluation data: 3.82330249236\n",
      "Accuracy on evaluation data: 915 / 10000\n",
      "\n",
      "Epoch 25 training complete\n",
      "Cost on training data: 4.02654569378\n",
      "Accuracy on training data: 4951 / 50000\n",
      "Cost on evaluation data: 4.02381314383\n",
      "Accuracy on evaluation data: 967 / 10000\n",
      "\n",
      "Epoch 26 training complete\n",
      "Cost on training data: 3.85255647089\n",
      "Accuracy on training data: 4988 / 50000\n",
      "Cost on evaluation data: 3.86886405801\n",
      "Accuracy on evaluation data: 961 / 10000\n",
      "\n",
      "Epoch 27 training complete\n",
      "Cost on training data: 3.67883988598\n",
      "Accuracy on training data: 5101 / 50000\n",
      "Cost on evaluation data: 3.69152069351\n",
      "Accuracy on evaluation data: 1030 / 10000\n",
      "\n",
      "Epoch 28 training complete\n",
      "Cost on training data: 3.57520765809\n",
      "Accuracy on training data: 4506 / 50000\n",
      "Cost on evaluation data: 3.56888926376\n",
      "Accuracy on evaluation data: 915 / 10000\n",
      "\n",
      "Epoch 29 training complete\n",
      "Cost on training data: 3.53692401777\n",
      "Accuracy on training data: 5678 / 50000\n",
      "Cost on evaluation data: 3.54807542794\n",
      "Accuracy on evaluation data: 1064 / 10000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([3.8896684925584322,\n",
       "  3.5374834786639178,\n",
       "  3.7450234795020045,\n",
       "  3.6050603220500022,\n",
       "  3.7268940140618461,\n",
       "  3.6595718586596653,\n",
       "  3.463030317397906,\n",
       "  3.8222742996198376,\n",
       "  3.5691788928371158,\n",
       "  3.6129623500522432,\n",
       "  3.4737627727097942,\n",
       "  3.5038878470677117,\n",
       "  3.591549907467531,\n",
       "  3.8028074201089317,\n",
       "  3.8208827304672832,\n",
       "  3.933506943871631,\n",
       "  3.8891651499625288,\n",
       "  3.5130795733394251,\n",
       "  3.4674057303750105,\n",
       "  3.8738822607328602,\n",
       "  3.5729073927641961,\n",
       "  4.4638706716008754,\n",
       "  3.9555624481188127,\n",
       "  4.1748371589532898,\n",
       "  3.8233024923625494,\n",
       "  4.0238131438285443,\n",
       "  3.8688640580136417,\n",
       "  3.6915206935087741,\n",
       "  3.5688892637639777,\n",
       "  3.5480754279417295],\n",
       " [1090,\n",
       "  915,\n",
       "  990,\n",
       "  991,\n",
       "  1090,\n",
       "  990,\n",
       "  1090,\n",
       "  983,\n",
       "  1090,\n",
       "  990,\n",
       "  1090,\n",
       "  1064,\n",
       "  967,\n",
       "  1030,\n",
       "  991,\n",
       "  983,\n",
       "  991,\n",
       "  967,\n",
       "  1030,\n",
       "  991,\n",
       "  990,\n",
       "  990,\n",
       "  1009,\n",
       "  983,\n",
       "  915,\n",
       "  967,\n",
       "  961,\n",
       "  1030,\n",
       "  915,\n",
       "  1064],\n",
       " [3.8884602550232508,\n",
       "  3.5267976628178115,\n",
       "  3.7402745747343058,\n",
       "  3.6164742488877581,\n",
       "  3.7477593136173266,\n",
       "  3.6575628395711184,\n",
       "  3.4724260405151854,\n",
       "  3.8165732535741457,\n",
       "  3.5788740399885768,\n",
       "  3.6079459652297836,\n",
       "  3.4814948288912304,\n",
       "  3.4953854824000183,\n",
       "  3.5706535703686049,\n",
       "  3.8121080743017552,\n",
       "  3.8180629413336891,\n",
       "  3.9157789031201182,\n",
       "  3.8750631541152867,\n",
       "  3.5030487987245715,\n",
       "  3.4571858685411136,\n",
       "  3.8756604918736488,\n",
       "  3.5728991728487514,\n",
       "  4.4581642824191476,\n",
       "  3.9728524420256788,\n",
       "  4.1783515030583338,\n",
       "  3.8320944636643817,\n",
       "  4.0265456937756694,\n",
       "  3.8525564708946374,\n",
       "  3.6788398859794103,\n",
       "  3.5752076580899006,\n",
       "  3.5369240177740444],\n",
       " [5175,\n",
       "  4506,\n",
       "  4968,\n",
       "  4932,\n",
       "  5175,\n",
       "  4968,\n",
       "  5175,\n",
       "  4859,\n",
       "  5175,\n",
       "  4968,\n",
       "  5175,\n",
       "  5678,\n",
       "  4951,\n",
       "  5101,\n",
       "  4932,\n",
       "  4859,\n",
       "  4932,\n",
       "  4951,\n",
       "  5101,\n",
       "  4932,\n",
       "  4968,\n",
       "  4968,\n",
       "  4842,\n",
       "  4859,\n",
       "  4506,\n",
       "  4951,\n",
       "  4988,\n",
       "  5101,\n",
       "  4506,\n",
       "  5678])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.SGD(training_data , 30, 10, 10.0,\n",
    "            lmbda = 1000.0,\n",
    "            evaluation_data= validation_data,\n",
    "            monitor_evaluation_cost=True,\n",
    "            monitor_evaluation_accuracy=True,\n",
    "            monitor_training_cost=True,\n",
    "            monitor_training_accuracy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Network([784, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/2.7/site-packages/ipykernel_launcher.py:155: RuntimeWarning: overflow encountered in exp\n",
      "/Library/Python/2.7/site-packages/ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in log\n",
      "  after removing the cwd from sys.path.\n",
      "/Library/Python/2.7/site-packages/ipykernel_launcher.py:4: RuntimeWarning: invalid value encountered in multiply\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on training data: inf\n",
      "Accuracy on training data: 96 / 1000\n",
      "Cost on evaluation data: inf\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "\n",
      "Epoch 1 training complete\n",
      "Cost on training data: inf\n",
      "Accuracy on training data: 96 / 1000\n",
      "Cost on evaluation data: inf\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/numpy/linalg/linalg.py:2050: RuntimeWarning: overflow encountered in multiply\n",
      "  return sqrt(add.reduce((x.conj() * x).real, axis=None))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 training complete\n",
      "Cost on training data: inf\n",
      "Accuracy on training data: 96 / 1000\n",
      "Cost on evaluation data: inf\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "\n",
      "Epoch 3 training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/2.7/site-packages/ipykernel_launcher.py:77: RuntimeWarning: overflow encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on training data: nan\n",
      "Accuracy on training data: 96 / 1000\n",
      "Cost on evaluation data: nan\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "\n",
      "Epoch 4 training complete\n",
      "Cost on training data: nan\n",
      "Accuracy on training data: 96 / 1000\n",
      "Cost on evaluation data: nan\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "\n",
      "Epoch 5 training complete\n",
      "Cost on training data: nan\n",
      "Accuracy on training data: 96 / 1000\n",
      "Cost on evaluation data: nan\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "\n",
      "Epoch 6 training complete\n",
      "Cost on training data: nan\n",
      "Accuracy on training data: 96 / 1000\n",
      "Cost on evaluation data: nan\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "\n",
      "Epoch 7 training complete\n",
      "Cost on training data: nan\n",
      "Accuracy on training data: 96 / 1000\n",
      "Cost on evaluation data: nan\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "\n",
      "Epoch 8 training complete\n",
      "Cost on training data: nan\n",
      "Accuracy on training data: 96 / 1000\n",
      "Cost on evaluation data: nan\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "\n",
      "Epoch 9 training complete\n",
      "Cost on training data: nan\n",
      "Accuracy on training data: 96 / 1000\n",
      "Cost on evaluation data: nan\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "\n",
      "Epoch 10 training complete\n",
      "Cost on training data: nan\n",
      "Accuracy on training data: 96 / 1000\n",
      "Cost on evaluation data: nan\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "\n",
      "Epoch 11 training complete\n",
      "Cost on training data: nan\n",
      "Accuracy on training data: 96 / 1000\n",
      "Cost on evaluation data: nan\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "\n",
      "Epoch 12 training complete\n",
      "Cost on training data: nan\n",
      "Accuracy on training data: 96 / 1000\n",
      "Cost on evaluation data: nan\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "\n",
      "Epoch 13 training complete\n",
      "Cost on training data: nan\n",
      "Accuracy on training data: 96 / 1000\n",
      "Cost on evaluation data: nan\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "\n",
      "Epoch 14 training complete\n",
      "Cost on training data: nan\n",
      "Accuracy on training data: 96 / 1000\n",
      "Cost on evaluation data: nan\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "\n",
      "Epoch 15 training complete\n",
      "Cost on training data: nan\n",
      "Accuracy on training data: 96 / 1000\n",
      "Cost on evaluation data: nan\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "\n",
      "Epoch 16 training complete\n",
      "Cost on training data: nan\n",
      "Accuracy on training data: 96 / 1000\n",
      "Cost on evaluation data: nan\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "\n",
      "Epoch 17 training complete\n",
      "Cost on training data: nan\n",
      "Accuracy on training data: 96 / 1000\n",
      "Cost on evaluation data: nan\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "\n",
      "Epoch 18 training complete\n",
      "Cost on training data: nan\n",
      "Accuracy on training data: 96 / 1000\n",
      "Cost on evaluation data: nan\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "\n",
      "Epoch 19 training complete\n",
      "Cost on training data: nan\n",
      "Accuracy on training data: 96 / 1000\n",
      "Cost on evaluation data: nan\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "\n",
      "Epoch 20 training complete\n",
      "Cost on training data: nan\n",
      "Accuracy on training data: 96 / 1000\n",
      "Cost on evaluation data: nan\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "\n",
      "Epoch 21 training complete\n",
      "Cost on training data: nan\n",
      "Accuracy on training data: 96 / 1000\n",
      "Cost on evaluation data: nan\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "\n",
      "Epoch 22 training complete\n",
      "Cost on training data: nan\n",
      "Accuracy on training data: 96 / 1000\n",
      "Cost on evaluation data: nan\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "\n",
      "Epoch 23 training complete\n",
      "Cost on training data: nan\n",
      "Accuracy on training data: 96 / 1000\n",
      "Cost on evaluation data: nan\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "\n",
      "Epoch 24 training complete\n",
      "Cost on training data: nan\n",
      "Accuracy on training data: 96 / 1000\n",
      "Cost on evaluation data: nan\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "\n",
      "Epoch 25 training complete\n",
      "Cost on training data: nan\n",
      "Accuracy on training data: 96 / 1000\n",
      "Cost on evaluation data: nan\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "\n",
      "Epoch 26 training complete\n",
      "Cost on training data: nan\n",
      "Accuracy on training data: 96 / 1000\n",
      "Cost on evaluation data: nan\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "\n",
      "Epoch 27 training complete\n",
      "Cost on training data: nan\n",
      "Accuracy on training data: 96 / 1000\n",
      "Cost on evaluation data: nan\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "\n",
      "Epoch 28 training complete\n",
      "Cost on training data: nan\n",
      "Accuracy on training data: 96 / 1000\n",
      "Cost on evaluation data: nan\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "\n",
      "Epoch 29 training complete\n",
      "Cost on training data: nan\n",
      "Accuracy on training data: 96 / 1000\n",
      "Cost on evaluation data: nan\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([inf,\n",
       "  inf,\n",
       "  inf,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan],\n",
       " [10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10],\n",
       " [inf,\n",
       "  inf,\n",
       "  inf,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan],\n",
       " [96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.SGD(training_data[:1000] , 30, 10, 10.0,\n",
    "            lmbda = 1000.0,\n",
    "            evaluation_data= validation_data[:100],\n",
    "            monitor_evaluation_cost=True,\n",
    "            monitor_evaluation_accuracy=True,\n",
    "            monitor_training_cost=True,\n",
    "            monitor_training_accuracy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "net=Network([784, 30, 30, 30, 30, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 training complete\n",
      "Cost on training data: 0.301551607628\n",
      "Accuracy on training data: 48752 / 50000\n",
      "Cost on evaluation data: 0.973229972296\n",
      "Accuracy on evaluation data: 9577 / 10000\n",
      "\n",
      "Epoch 1 training complete\n",
      "Cost on training data: 0.254345538727\n",
      "Accuracy on training data: 49224 / 50000\n",
      "Cost on evaluation data: 0.946371162498\n",
      "Accuracy on evaluation data: 9641 / 10000\n",
      "\n",
      "Epoch 2 training complete\n",
      "Cost on training data: 0.253444456024\n",
      "Accuracy on training data: 49244 / 50000\n",
      "Cost on evaluation data: 0.941521932504\n",
      "Accuracy on evaluation data: 9653 / 10000\n",
      "\n",
      "Epoch 3 training complete\n",
      "Cost on training data: 0.272073358529\n",
      "Accuracy on training data: 49057 / 50000\n",
      "Cost on evaluation data: 0.963686794202\n",
      "Accuracy on evaluation data: 9632 / 10000\n",
      "\n",
      "Epoch 4 training complete\n",
      "Cost on training data: 0.255725351011\n",
      "Accuracy on training data: 49207 / 50000\n",
      "Cost on evaluation data: 0.956148476365\n",
      "Accuracy on evaluation data: 9635 / 10000\n",
      "\n",
      "Epoch 5 training complete\n",
      "Cost on training data: 0.275632071835\n",
      "Accuracy on training data: 49012 / 50000\n",
      "Cost on evaluation data: 0.970947958828\n",
      "Accuracy on evaluation data: 9630 / 10000\n",
      "\n",
      "Epoch 6 training complete\n",
      "Cost on training data: 0.255440189146\n",
      "Accuracy on training data: 49248 / 50000\n",
      "Cost on evaluation data: 0.946190308616\n",
      "Accuracy on evaluation data: 9653 / 10000\n",
      "\n",
      "Epoch 7 training complete\n",
      "Cost on training data: 0.246617040139\n",
      "Accuracy on training data: 49314 / 50000\n",
      "Cost on evaluation data: 0.949564111779\n",
      "Accuracy on evaluation data: 9644 / 10000\n",
      "\n",
      "Epoch 8 training complete\n",
      "Cost on training data: 0.24505482879\n",
      "Accuracy on training data: 49317 / 50000\n",
      "Cost on evaluation data: 0.937020972854\n",
      "Accuracy on evaluation data: 9678 / 10000\n",
      "\n",
      "Epoch 9 training complete\n",
      "Cost on training data: 0.321014606665\n",
      "Accuracy on training data: 48536 / 50000\n",
      "Cost on evaluation data: 1.01132170108\n",
      "Accuracy on evaluation data: 9570 / 10000\n",
      "\n",
      "Epoch 10 training complete\n",
      "Cost on training data: 0.242461123371\n",
      "Accuracy on training data: 49335 / 50000\n",
      "Cost on evaluation data: 0.952226603673\n",
      "Accuracy on evaluation data: 9652 / 10000\n",
      "\n",
      "Epoch 11 training complete\n",
      "Cost on training data: 0.243817376888\n",
      "Accuracy on training data: 49301 / 50000\n",
      "Cost on evaluation data: 0.958631780005\n",
      "Accuracy on evaluation data: 9650 / 10000\n",
      "\n",
      "Epoch 12 training complete\n",
      "Cost on training data: 0.23878054808\n",
      "Accuracy on training data: 49408 / 50000\n",
      "Cost on evaluation data: 0.944390631021\n",
      "Accuracy on evaluation data: 9670 / 10000\n",
      "\n",
      "Epoch 13 training complete\n",
      "Cost on training data: 0.237084771938\n",
      "Accuracy on training data: 49390 / 50000\n",
      "Cost on evaluation data: 0.941993915127\n",
      "Accuracy on evaluation data: 9661 / 10000\n",
      "\n",
      "Epoch 14 training complete\n",
      "Cost on training data: 0.334188760927\n",
      "Accuracy on training data: 48520 / 50000\n",
      "Cost on evaluation data: 1.04178726397\n",
      "Accuracy on evaluation data: 9525 / 10000\n",
      "\n",
      "Epoch 15 training complete\n",
      "Cost on training data: 0.244509408112\n",
      "Accuracy on training data: 49333 / 50000\n",
      "Cost on evaluation data: 0.946135501715\n",
      "Accuracy on evaluation data: 9674 / 10000\n",
      "\n",
      "Epoch 16 training complete\n",
      "Cost on training data: 0.264203001472\n",
      "Accuracy on training data: 49148 / 50000\n",
      "Cost on evaluation data: 0.970412003402\n",
      "Accuracy on evaluation data: 9637 / 10000\n",
      "\n",
      "Epoch 17 training complete\n",
      "Cost on training data: 0.254141118113\n",
      "Accuracy on training data: 49236 / 50000\n",
      "Cost on evaluation data: 0.980439358122\n",
      "Accuracy on evaluation data: 9608 / 10000\n",
      "\n",
      "Epoch 18 training complete\n",
      "Cost on training data: 0.23753704172\n",
      "Accuracy on training data: 49373 / 50000\n",
      "Cost on evaluation data: 0.951190813797\n",
      "Accuracy on evaluation data: 9665 / 10000\n",
      "\n",
      "Epoch 19 training complete\n",
      "Cost on training data: 0.255569184213\n",
      "Accuracy on training data: 49203 / 50000\n",
      "Cost on evaluation data: 0.95973609029\n",
      "Accuracy on evaluation data: 9656 / 10000\n",
      "\n",
      "Epoch 20 training complete\n",
      "Cost on training data: 0.254584536144\n",
      "Accuracy on training data: 49211 / 50000\n",
      "Cost on evaluation data: 0.964346621904\n",
      "Accuracy on evaluation data: 9627 / 10000\n",
      "\n",
      "Epoch 21 training complete\n",
      "Cost on training data: 0.238363071301\n",
      "Accuracy on training data: 49380 / 50000\n",
      "Cost on evaluation data: 0.943635266998\n",
      "Accuracy on evaluation data: 9681 / 10000\n",
      "\n",
      "Epoch 22 training complete\n",
      "Cost on training data: 0.25990949389\n",
      "Accuracy on training data: 49152 / 50000\n",
      "Cost on evaluation data: 0.972705173073\n",
      "Accuracy on evaluation data: 9645 / 10000\n",
      "\n",
      "Epoch 23 training complete\n",
      "Cost on training data: 0.244441440778\n",
      "Accuracy on training data: 49321 / 50000\n",
      "Cost on evaluation data: 0.962510466208\n",
      "Accuracy on evaluation data: 9661 / 10000\n",
      "\n",
      "Epoch 24 training complete\n",
      "Cost on training data: 0.23695748825\n",
      "Accuracy on training data: 49407 / 50000\n",
      "Cost on evaluation data: 0.954127856371\n",
      "Accuracy on evaluation data: 9663 / 10000\n",
      "\n",
      "Epoch 25 training complete\n",
      "Cost on training data: 0.244237221331\n",
      "Accuracy on training data: 49319 / 50000\n",
      "Cost on evaluation data: 0.942317682308\n",
      "Accuracy on evaluation data: 9688 / 10000\n",
      "\n",
      "Epoch 26 training complete\n",
      "Cost on training data: 0.245974476063\n",
      "Accuracy on training data: 49336 / 50000\n",
      "Cost on evaluation data: 0.94780074794\n",
      "Accuracy on evaluation data: 9685 / 10000\n",
      "\n",
      "Epoch 27 training complete\n",
      "Cost on training data: 0.249563990575\n",
      "Accuracy on training data: 49292 / 50000\n",
      "Cost on evaluation data: 0.974945034835\n",
      "Accuracy on evaluation data: 9641 / 10000\n",
      "\n",
      "Epoch 28 training complete\n",
      "Cost on training data: 0.250283157203\n",
      "Accuracy on training data: 49260 / 50000\n",
      "Cost on evaluation data: 0.957588496327\n",
      "Accuracy on evaluation data: 9670 / 10000\n",
      "\n",
      "Epoch 29 training complete\n",
      "Cost on training data: 0.23687818324\n",
      "Accuracy on training data: 49389 / 50000\n",
      "Cost on evaluation data: 0.945985218921\n",
      "Accuracy on evaluation data: 9687 / 10000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.97322997229553898,\n",
       "  0.94637116249759223,\n",
       "  0.94152193250439375,\n",
       "  0.96368679420239356,\n",
       "  0.95614847636467626,\n",
       "  0.97094795882808516,\n",
       "  0.94619030861605125,\n",
       "  0.94956411177918421,\n",
       "  0.93702097285393049,\n",
       "  1.0113217010800684,\n",
       "  0.95222660367318979,\n",
       "  0.95863178000519977,\n",
       "  0.94439063102061505,\n",
       "  0.94199391512718711,\n",
       "  1.0417872639688703,\n",
       "  0.94613550171533589,\n",
       "  0.97041200340234357,\n",
       "  0.98043935812173866,\n",
       "  0.95119081379660553,\n",
       "  0.95973609028994478,\n",
       "  0.96434662190403264,\n",
       "  0.94363526699780342,\n",
       "  0.97270517307292592,\n",
       "  0.96251046620763026,\n",
       "  0.95412785637059616,\n",
       "  0.94231768230809876,\n",
       "  0.94780074793993074,\n",
       "  0.97494503483470329,\n",
       "  0.95758849632654186,\n",
       "  0.94598521892111687],\n",
       " [9577,\n",
       "  9641,\n",
       "  9653,\n",
       "  9632,\n",
       "  9635,\n",
       "  9630,\n",
       "  9653,\n",
       "  9644,\n",
       "  9678,\n",
       "  9570,\n",
       "  9652,\n",
       "  9650,\n",
       "  9670,\n",
       "  9661,\n",
       "  9525,\n",
       "  9674,\n",
       "  9637,\n",
       "  9608,\n",
       "  9665,\n",
       "  9656,\n",
       "  9627,\n",
       "  9681,\n",
       "  9645,\n",
       "  9661,\n",
       "  9663,\n",
       "  9688,\n",
       "  9685,\n",
       "  9641,\n",
       "  9670,\n",
       "  9687],\n",
       " [0.30155160762800332,\n",
       "  0.25434553872693322,\n",
       "  0.25344445602363541,\n",
       "  0.27207335852915726,\n",
       "  0.25572535101058635,\n",
       "  0.27563207183456623,\n",
       "  0.25544018914609179,\n",
       "  0.24661704013883576,\n",
       "  0.24505482879019364,\n",
       "  0.32101460666459192,\n",
       "  0.24246112337055628,\n",
       "  0.24381737688826438,\n",
       "  0.23878054808026894,\n",
       "  0.23708477193845798,\n",
       "  0.3341887609270327,\n",
       "  0.24450940811152216,\n",
       "  0.26420300147186537,\n",
       "  0.25414111811304607,\n",
       "  0.23753704171980278,\n",
       "  0.25556918421329472,\n",
       "  0.25458453614393689,\n",
       "  0.23836307130075482,\n",
       "  0.25990949389030582,\n",
       "  0.24444144077848193,\n",
       "  0.23695748824972068,\n",
       "  0.24423722133115425,\n",
       "  0.24597447606274409,\n",
       "  0.24956399057545781,\n",
       "  0.25028315720265581,\n",
       "  0.23687818323970913],\n",
       " [48752,\n",
       "  49224,\n",
       "  49244,\n",
       "  49057,\n",
       "  49207,\n",
       "  49012,\n",
       "  49248,\n",
       "  49314,\n",
       "  49317,\n",
       "  48536,\n",
       "  49335,\n",
       "  49301,\n",
       "  49408,\n",
       "  49390,\n",
       "  48520,\n",
       "  49333,\n",
       "  49148,\n",
       "  49236,\n",
       "  49373,\n",
       "  49203,\n",
       "  49211,\n",
       "  49380,\n",
       "  49152,\n",
       "  49321,\n",
       "  49407,\n",
       "  49319,\n",
       "  49336,\n",
       "  49292,\n",
       "  49260,\n",
       "  49389])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.SGD(training_data, 30, 10, 0.1, lmbda=5.0,\n",
    "        evaluation_data= validation_data,\n",
    "            monitor_evaluation_cost=True,\n",
    "            monitor_evaluation_accuracy=True,\n",
    "            monitor_training_cost=True,\n",
    "            monitor_training_accuracy=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
